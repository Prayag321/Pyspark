{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHT-WlEop8tg"
      },
      "source": [
        "\"\"\"<br>\n",
        "@Author: Prayag Bhoir<br>\n",
        "@Date: 3-09-2024<br>\n",
        "@Last Modified by: Prayag Bhoir<br>\n",
        "@Last Modified time: 3-09-2024<br>\n",
        "@Title : Python programs for word count using Pyspark <br>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDXqcwG9l6l7",
        "outputId": "4e8f55f4-1388-4931-bb34-1bfe0e169230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "kW-jyJO-mTyp"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext,SparkConf\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "bKng-yU1nTQ0"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"WordCount\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_abyxZTt0dI"
      },
      "source": [
        "## Word count using text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "-jdSCztXnjDF"
      },
      "outputs": [],
      "source": [
        "# Load a text file into a DataFrame\n",
        "text_file_df = spark.read.text(\"/content/text.txt\")\n",
        "# Convert DataFrame to RDD\n",
        "text_file_rdd = text_file_df.rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi-L4AAcrViv",
        "outputId": "71099845-3acd-45c9-b0b5-82d833d6e249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Row(value=\"Today, I want to talk about the Global Happiness Index and India's position on it. The Global Happiness Index is a measure of well-being that evaluates how happy people are in different countries. It considers several factors, including income, life expectancy, social support, freedom to make life choices, and perceptions of corruption.\")]\n"
          ]
        }
      ],
      "source": [
        "# Checking text file\n",
        "print(text_file_rdd.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "R4h-y0B0pOG6"
      },
      "outputs": [],
      "source": [
        "# Perform word count using RDD operations\n",
        "word_counts = text_file_rdd.flatMap(lambda line: line[0].split()) \\\n",
        "    .map(lambda word: (word, 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhfoSXEkn-EQ",
        "outputId": "e442fe36-9646-4b1e-adf5-f0c90436ef72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Today, : 1\n",
            "I : 1\n",
            "want : 1\n",
            "to : 2\n",
            "talk : 1\n",
            "about : 1\n",
            "the : 1\n",
            "Global : 2\n",
            "Happiness : 2\n",
            "Index : 2\n",
            "and : 2\n",
            "India's : 1\n",
            "position : 1\n",
            "on : 1\n",
            "it. : 1\n",
            "The : 1\n",
            "is : 1\n",
            "a : 1\n",
            "measure : 1\n",
            "of : 2\n",
            "well-being : 1\n",
            "that : 1\n",
            "evaluates : 1\n",
            "how : 1\n",
            "happy : 1\n",
            "people : 1\n",
            "are : 1\n",
            "in : 1\n",
            "different : 1\n",
            "countries. : 1\n",
            "It : 1\n",
            "considers : 1\n",
            "several : 1\n",
            "factors, : 1\n",
            "including : 1\n",
            "income, : 1\n",
            "life : 2\n",
            "expectancy, : 1\n",
            "social : 1\n",
            "support, : 1\n",
            "freedom : 1\n",
            "make : 1\n",
            "choices, : 1\n",
            "perceptions : 1\n",
            "corruption. : 1\n"
          ]
        }
      ],
      "source": [
        "# Collect the word counts to a list and print them\n",
        "for word ,count in word_counts.collect():\n",
        "  print(f\"{word} : {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "LCwJtoZcrnDr"
      },
      "outputs": [],
      "source": [
        "# Stop the session\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_FPrrY8z60v"
      },
      "source": [
        "## Word count using JSON with sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "uK7DiRTL3Mkd"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "5k8-GC7azG2S"
      },
      "outputs": [],
      "source": [
        "# Create a SparkConf object\n",
        "conf = SparkConf().setAppName(\"MyApp\").setMaster(\"local[*]\")\n",
        "\n",
        "# Initialize a SparkContext object\n",
        "sc = SparkContext(conf=conf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "febWJATj5THz"
      },
      "outputs": [],
      "source": [
        "# Read json file\n",
        "json_text_rdd = sc.textFile(\"/content/text.json\")\n",
        "\n",
        "# parsed the json\n",
        "parsed_rdd = json_text_rdd.map(lambda x: json.loads(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFhLaB6izfoG",
        "outputId": "24d49919-d094-45f8-e0c1-e2e231c8aff1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['{\"paragraph\": \"In the quiet village nestled between the towering mountains, life moved at a slow, predictable pace. The villagers, known for their warm hospitality and simple way of life, gathered every evening at the central square to share stories passed down through generations. The ancient oak tree, standing tall in the middle of the square, was a silent witness to the countless tales of love, loss, and triumph. As the sun dipped below the horizon, casting a golden hue over the cobblestone streets, the village seemed to glow with an ethereal light, as if the very air was charged with the memories of the past.\"}']"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check text file\n",
        "json_text_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "LhIHdsOs5mTH"
      },
      "outputs": [],
      "source": [
        "# Extract paragraph and perform word count\n",
        "paragraph_rdd = parsed_rdd.map(lambda x: x[\"paragraph\"])\n",
        "\n",
        "words_rdd = paragraph_rdd.flatMap(lambda x: x.split()) \\\n",
        "            .map(lambda word: (word, 1)) \\\n",
        "            .reduceByKey(lambda a, b: a + b)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDOGMCa5tIm",
        "outputId": "af129a38-15b9-4463-d1bb-c33609e37407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quiet: 1\n",
            "nestled: 1\n",
            "mountains,: 1\n",
            "at: 2\n",
            "pace.: 1\n",
            "The: 2\n",
            "known: 1\n",
            "simple: 1\n",
            "way: 1\n",
            "of: 4\n",
            "life,: 1\n",
            "gathered: 1\n",
            "central: 1\n",
            "square: 1\n",
            "share: 1\n",
            "passed: 1\n",
            "down: 1\n",
            "generations.: 1\n",
            "ancient: 1\n",
            "oak: 1\n",
            "tree,: 1\n",
            "in: 1\n",
            "middle: 1\n",
            "square,: 1\n",
            "was: 2\n",
            "witness: 1\n",
            "triumph.: 1\n",
            "sun: 1\n",
            "dipped: 1\n",
            "below: 1\n",
            "horizon,: 1\n",
            "casting: 1\n",
            "hue: 1\n",
            "streets,: 1\n",
            "seemed: 1\n",
            "an: 1\n",
            "light,: 1\n",
            "as: 1\n",
            "very: 1\n",
            "memories: 1\n",
            "past.: 1\n",
            "In: 1\n",
            "the: 13\n",
            "village: 2\n",
            "between: 1\n",
            "towering: 1\n",
            "life: 1\n",
            "moved: 1\n",
            "a: 3\n",
            "slow,: 1\n",
            "predictable: 1\n",
            "villagers,: 1\n",
            "for: 1\n",
            "their: 1\n",
            "warm: 1\n",
            "hospitality: 1\n",
            "and: 2\n",
            "every: 1\n",
            "evening: 1\n",
            "to: 3\n",
            "stories: 1\n",
            "through: 1\n",
            "standing: 1\n",
            "tall: 1\n",
            "silent: 1\n",
            "countless: 1\n",
            "tales: 1\n",
            "love,: 1\n",
            "loss,: 1\n",
            "As: 1\n",
            "golden: 1\n",
            "over: 1\n",
            "cobblestone: 1\n",
            "glow: 1\n",
            "with: 2\n",
            "ethereal: 1\n",
            "if: 1\n",
            "air: 1\n",
            "charged: 1\n"
          ]
        }
      ],
      "source": [
        "# Collect and print results\n",
        "word_counts = words_rdd.collect()\n",
        "\n",
        "for word, count in word_counts:\n",
        "    print(f\"{word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "aze0r8b0_SlZ"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
